{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe9ef2e",
   "metadata": {},
   "source": [
    "## Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b6c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import os\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0671d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10282.6</td>\n",
       "      <td>“machine intelligence is the last invention th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10744.4</td>\n",
       "      <td>introduction    where is this disruptive techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11206.2</td>\n",
       "      <td>in future or in upcoming years humans and mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12129.8</td>\n",
       "      <td>machine learning techniques may have been used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123.0</td>\n",
       "      <td>telemedicine, the use of technology to diagnos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                            article\n",
       "0    10282.6  “machine intelligence is the last invention th...\n",
       "1    10744.4  introduction    where is this disruptive techn...\n",
       "2    11206.2  in future or in upcoming years humans and mach...\n",
       "3    12129.8  machine learning techniques may have been used...\n",
       "4      123.0  telemedicine, the use of technology to diagnos..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading articles\n",
    "folder = 'C:\\\\Users\\\\rohit\\\\Python\\\\drive-download-20230909T190744Z-001\\\\extracted_articles'\n",
    "\n",
    "filenames = []\n",
    "contents = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            file_content = file.read()\n",
    "        filenames.append(filename.strip('.txt'))\n",
    "        contents.append(file_content)\n",
    "\n",
    "df = pd.DataFrame({'article_id': filenames, 'article': contents})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69958dea",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8608d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a613816",
   "metadata": {},
   "source": [
    "#### Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c6d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54de5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.article.values.tolist()\n",
    "\n",
    "data_words = remove_stopwords(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff9b45",
   "metadata": {},
   "source": [
    "#### Positive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8136fcb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting positive words\n",
    "pos = pd.read_csv(r'C:\\Users\\rohit\\Python\\drive-download-20230909T190744Z-001\\MasterDictionary\\positive-words.txt', header = None)\n",
    "pos.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3adf17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating scores\n",
    "pos_score = []\n",
    "for words in data_words:\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        if word in list(pos.words):\n",
    "            score += 1\n",
    "    pos_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d11ac4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding positive score as a new column in dataframe\n",
    "df['positive_score'] = pos_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6a822",
   "metadata": {},
   "source": [
    "#### Negative score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8683805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting negative words\n",
    "neg = pd.read_csv(r'C:\\Users\\rohit\\Python\\drive-download-20230909T190744Z-001\\MasterDictionary\\negative-words.txt', header = None, encoding='latin-1')\n",
    "neg.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9074f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating scores\n",
    "neg_score = []\n",
    "for words in data_words:\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        if word in list(neg.words):\n",
    "            score += 1\n",
    "    neg_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e71f24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding negaitve score as a new column in dataframe\n",
    "df['negative_score'] = neg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fbc225",
   "metadata": {},
   "source": [
    "#### Polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419b5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity_score'] = (df['positive_score'] - df['negative_score'])/((df['positive_score'] + df['negative_score']) + 0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd6d68",
   "metadata": {},
   "source": [
    "#### Subjectivity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bdf6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = [len(words) for words in data_words]\n",
    "df['subjectivity_score'] = (df['positive_score'] + df['negative_score'])/total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebb470",
   "metadata": {},
   "source": [
    "#### Average sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6828dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_sentence_length'] = [total/len(data_words) for total in total_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d01e5",
   "metadata": {},
   "source": [
    "#### Complex word percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d70163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming that a complex word is a word which is more than 10 characters long\n",
    "complex_words_list = [[word for word in words if len(word) > 10] for words in data_words]\n",
    "\n",
    "# Calculate the percentage of complex words\n",
    "complex_words_percentages = [(len(complex_words)/sum(total_words))*100 for complex_words in complex_words_list]\n",
    "df['complex_words_percentages'] = complex_words_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ecd31c",
   "metadata": {},
   "source": [
    "#### Fog index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488da79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fog_sum = df['average_sentence_length'] + df['complex_words_percentages']\n",
    "df['fog_index'] = 0.4 * fog_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad755aef",
   "metadata": {},
   "source": [
    "#### Average number of words per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0076df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number is words per sentence is same as average_sentence_length which we have already calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46868698",
   "metadata": {},
   "source": [
    "#### Complex words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25d8d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_words_count = df['complex_words_percentages'] * total_words\n",
    "df['complex_words_count'] = complex_words_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3bbbf",
   "metadata": {},
   "source": [
    "#### Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04154201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d2212",
   "metadata": {},
   "source": [
    "#### Syllable count per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de06b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = []\n",
    "for words in data_words:\n",
    "    vowels = 0\n",
    "    for word in words:\n",
    "        vowel_count = len([char for char in word if char in 'aeiouy'])\n",
    "        vowels += vowel_count\n",
    "    avg_vowel = vowels/len(words)\n",
    "    syllables.append(avg_vowel)\n",
    "\n",
    "df['syllabel_per_word'] = syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dede41",
   "metadata": {},
   "source": [
    "#### Personal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c62c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = ['i', 'we', 'my', 'ours', 'us']\n",
    "pronouns_count = [len([word for word in words if word in pronouns]) for words in data_words]\n",
    "df['personal_pronouns'] = pronouns_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004bf5d",
   "metadata": {},
   "source": [
    "#### Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f58edc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_len = [sum(len(word) for word in words) / len(words) for words in data_words]\n",
    "df['average_word_length'] = avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e819aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>complex_words_percentages</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>complex_words_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>syllabel_per_word</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>average_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10282.6</td>\n",
       "      <td>“machine intelligence is the last invention th...</td>\n",
       "      <td>71</td>\n",
       "      <td>29</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.105374</td>\n",
       "      <td>9.303922</td>\n",
       "      <td>0.107839</td>\n",
       "      <td>3.764704</td>\n",
       "      <td>102.338934</td>\n",
       "      <td>949</td>\n",
       "      <td>2.696523</td>\n",
       "      <td>6</td>\n",
       "      <td>6.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10744.4</td>\n",
       "      <td>introduction    where is this disruptive techn...</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.123348</td>\n",
       "      <td>6.676471</td>\n",
       "      <td>0.072864</td>\n",
       "      <td>2.699734</td>\n",
       "      <td>49.620379</td>\n",
       "      <td>681</td>\n",
       "      <td>2.657856</td>\n",
       "      <td>3</td>\n",
       "      <td>6.722467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11206.2</td>\n",
       "      <td>in future or in upcoming years humans and mach...</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>3.941176</td>\n",
       "      <td>0.032060</td>\n",
       "      <td>1.589295</td>\n",
       "      <td>12.888183</td>\n",
       "      <td>402</td>\n",
       "      <td>2.671642</td>\n",
       "      <td>2</td>\n",
       "      <td>6.718905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12129.8</td>\n",
       "      <td>machine learning techniques may have been used...</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.147583</td>\n",
       "      <td>3.852941</td>\n",
       "      <td>0.017487</td>\n",
       "      <td>1.548171</td>\n",
       "      <td>6.872532</td>\n",
       "      <td>393</td>\n",
       "      <td>2.442748</td>\n",
       "      <td>0</td>\n",
       "      <td>6.325700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123.0</td>\n",
       "      <td>telemedicine, the use of technology to diagnos...</td>\n",
       "      <td>89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.113682</td>\n",
       "      <td>9.745098</td>\n",
       "      <td>0.189446</td>\n",
       "      <td>3.973818</td>\n",
       "      <td>188.309701</td>\n",
       "      <td>994</td>\n",
       "      <td>3.056338</td>\n",
       "      <td>0</td>\n",
       "      <td>7.338028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                            article  \\\n",
       "0    10282.6  “machine intelligence is the last invention th...   \n",
       "1    10744.4  introduction    where is this disruptive techn...   \n",
       "2    11206.2  in future or in upcoming years humans and mach...   \n",
       "3    12129.8  machine learning techniques may have been used...   \n",
       "4      123.0  telemedicine, the use of technology to diagnos...   \n",
       "\n",
       "   positive_score  negative_score  polarity_score  subjectivity_score  \\\n",
       "0              71              29        0.420000            0.105374   \n",
       "1              58              26        0.380952            0.123348   \n",
       "2              28              12        0.400000            0.099502   \n",
       "3              44              14        0.517241            0.147583   \n",
       "4              89              24        0.575221            0.113682   \n",
       "\n",
       "   average_sentence_length  complex_words_percentages  fog_index  \\\n",
       "0                 9.303922                   0.107839   3.764704   \n",
       "1                 6.676471                   0.072864   2.699734   \n",
       "2                 3.941176                   0.032060   1.589295   \n",
       "3                 3.852941                   0.017487   1.548171   \n",
       "4                 9.745098                   0.189446   3.973818   \n",
       "\n",
       "   complex_words_count  word_count  syllabel_per_word  personal_pronouns  \\\n",
       "0           102.338934         949           2.696523                  6   \n",
       "1            49.620379         681           2.657856                  3   \n",
       "2            12.888183         402           2.671642                  2   \n",
       "3             6.872532         393           2.442748                  0   \n",
       "4           188.309701         994           3.056338                  0   \n",
       "\n",
       "   average_word_length  \n",
       "0             6.808219  \n",
       "1             6.722467  \n",
       "2             6.718905  \n",
       "3             6.325700  \n",
       "4             7.338028  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccccaec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
